{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Download the list of S&P 500 companies from Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "tables = pd.read_html(url)\n",
    "sp500_table = tables[0]\n",
    "sp500_symbols = sp500_table['Symbol'].tolist()\n",
    "selected_symbols = sp500_symbols\n",
    "\n",
    "# Download Historical Data\n",
    "def fetch_data(symbol, retries=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            data = yf.download(symbol, start='2020-01-01', end='2024-07-31')[['Adj Close', 'Volume']]\n",
    "            if data.empty:\n",
    "                raise ValueError(f\"No data found for {symbol}\")\n",
    "            return symbol, data\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed for {symbol}: {e}\")\n",
    "            sleep(randint(1, 3))\n",
    "    return symbol, None\n",
    "\n",
    "# Use threading to download data for each stock\n",
    "data_frames = {}\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = {executor.submit(fetch_data, symbol): symbol for symbol in selected_symbols}\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            symbol, data = result\n",
    "            if data is not None:\n",
    "                data_frames[symbol] = data\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "valid_data = {symbol: data for symbol, data in data_frames.items() if data is not None}\n",
    "prices = pd.DataFrame({symbol: data['Adj Close'] for symbol, data in valid_data.items()})\n",
    "volumes = pd.DataFrame({symbol: data['Volume'] for symbol, data in valid_data.items()})\n",
    "\n",
    "prices = prices.dropna(axis=1, how='all')\n",
    "volumes = volumes.dropna(axis=1, how='all')\n",
    "\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "avg_corr = returns.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting the Network --- #\n",
    "notional_values = prices * volumes\n",
    "notional_values = notional_values.mean(axis=0)  # Average notional value over the period\n",
    "\n",
    "# Normalize notional values for plotting\n",
    "min_notional = notional_values.min()\n",
    "max_notional = notional_values.max()\n",
    "normalized_notional = 10 + (40 * (notional_values - min_notional) / (max_notional - min_notional))\n",
    "\n",
    "notional_df = pd.DataFrame({'notional_value': notional_values, 'normalized_notional': normalized_notional})\n",
    "\n",
    "# Plotting function\n",
    "def plot_avg_corr_network(correlations, notional_df, threshold=0.4, n_clusters=5, max_connections=6):\n",
    "    correlations = correlations.dropna(axis=0, how='any').dropna(axis=1, how='any')\n",
    "    correlations = correlations.applymap(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for stock in correlations.columns:\n",
    "        G.add_node(stock, notional_value=notional_df.loc[stock, 'normalized_notional'])\n",
    "    \n",
    "    for i in correlations.columns:\n",
    "        node_correlations = correlations[i].sort_values(ascending=False)\n",
    "        connections = 0\n",
    "        for j in node_correlations.index:\n",
    "            if i != j and node_correlations[j] > threshold and connections < max_connections:\n",
    "                G.add_edge(i, j, weight=node_correlations[j])\n",
    "                connections += 1\n",
    "\n",
    "    pos = nx.spring_layout(G, k=0.1)\n",
    "    \n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', assign_labels='discretize').fit(correlations)\n",
    "    labels = clustering.labels_\n",
    "    \n",
    "    edge_traces = []\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        trace = go.Scatter(\n",
    "            x=[x0, x1, None], y=[y0, y1, None],\n",
    "            line=dict(width=edge[2]['weight'], color='#888'),\n",
    "            hoverinfo='none',\n",
    "            mode='lines')\n",
    "        edge_traces.append(trace)\n",
    "\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_color = []\n",
    "    node_size = []\n",
    "    for i, node in enumerate(G.nodes()):\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_color.append(labels[i])\n",
    "        node_size.append(G.nodes[node]['notional_value'])\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers+text',\n",
    "        text=[node for node in G.nodes()],\n",
    "        textposition=\"bottom center\",\n",
    "        hoverinfo='text',\n",
    "        marker=dict(\n",
    "            showscale=True,\n",
    "            colorscale='Rainbow',\n",
    "            size=node_size,\n",
    "            color=node_color,\n",
    "            colorbar=dict(\n",
    "                thickness=15,\n",
    "                title='Cluster Group',\n",
    "                xanchor='left',\n",
    "                titleside='right'\n",
    "            ),\n",
    "            line_width=2))\n",
    "\n",
    "    node_adjacencies = []\n",
    "    node_text = []\n",
    "    for node, adjacencies in enumerate(G.adjacency()):\n",
    "        node_adjacencies.append(len(adjacencies[1]))\n",
    "        node_text.append(f'{adjacencies[0]}')\n",
    "\n",
    "    node_trace.marker.color = node_color\n",
    "    node_trace.text = node_text\n",
    "\n",
    "    fig = go.Figure(data=edge_traces + [node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title='Stock Correlation Network',\n",
    "                        titlefont_size=16,\n",
    "                        width=1800,\n",
    "                        height=1400,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20,l=5,r=5,t=40),\n",
    "                        annotations=[dict(\n",
    "                            text=\"\",\n",
    "                            showarrow=False,\n",
    "                            xref=\"paper\", yref=\"paper\")],\n",
    "                        xaxis=dict(showgrid=False, zeroline=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False))\n",
    "                    )\n",
    "    fig.show()\n",
    "\n",
    "plot_avg_corr_network(avg_corr, notional_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ranks Top 10 Highest Correlated Stocks with a Given Stock --- #\n",
    "\n",
    "# Ensure ticker data is present\n",
    "ticker = input(\"Enter the ticker symbol: \")\n",
    "if ticker not in avg_corr.columns:\n",
    "    raise ValueError(f'{ticker} data is not available in the dataset.')\n",
    "\n",
    "# Find the highest correlated stocks \n",
    "target_stock = ticker\n",
    "correlations_with_target = avg_corr[target_stock]\n",
    "\n",
    "# Sort the correlations in descending order and exclude the target stock itself\n",
    "highest_correlations = correlations_with_target.sort_values(ascending=False).drop(target_stock)\n",
    "\n",
    "# Display the top 10 highest correlated stocks\n",
    "top_10_highest_correlated_stocks = highest_correlations.head(10)\n",
    "print(f'Top 10 highest correlated stocks with {ticker}:')\n",
    "print(top_10_highest_correlated_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a Synthetic Version of a Stock --- #\n",
    "\n",
    "def recreate_ticker(target_ticker, returns, exclude_tickers=[], num_tickers=10, display_plot=True):\n",
    "    \n",
    "    if target_ticker in exclude_tickers:\n",
    "        exclude_tickers.remove(target_ticker)\n",
    "    \n",
    "    # Calculate correlations with the target ticker\n",
    "    correlations = returns.corr()[target_ticker].drop(target_ticker)\n",
    "    \n",
    "    # Select the top num_tickers based on correlation\n",
    "    top_tickers = correlations.abs().sort_values(ascending=False).head(num_tickers).index.tolist()\n",
    "    \n",
    "    # Exclude additional specified tickers\n",
    "    top_tickers = [ticker for ticker in top_tickers if ticker not in exclude_tickers]\n",
    "    \n",
    "    X = returns[top_tickers]\n",
    "    y = returns[target_ticker]\n",
    "    \n",
    "    # Fit the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get the weights\n",
    "    weights = model.coef_\n",
    "    tickers = X.columns\n",
    "    ticker_weights = pd.DataFrame({'Ticker': tickers, 'Weight': weights})\n",
    "    \n",
    "    # Recreate the target ticker\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    if display_plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(returns.index, y, label=target_ticker)\n",
    "        plt.plot(returns.index, y_pred, label='Synthetic ' + target_ticker)\n",
    "        plt.title(f'Real vs Synthetic {target_ticker}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return ticker_weights, y_pred\n",
    "\n",
    "# Example usage\n",
    "target_ticker = 'TSLA'  # Replace with your target ticker\n",
    "exclude_tickers = ['GOOGL', 'MSFT']  # Replace with any tickers you want to exclude from the synthetic creation\n",
    "ticker_weights, synthetic_returns = recreate_ticker(target_ticker, returns, exclude_tickers)\n",
    "\n",
    "print(ticker_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
